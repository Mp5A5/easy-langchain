{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sugarforever/wtf-langchain/blob/main/01_Hello_Langchain/Hello_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "F3PJ9w-JGMbL"
   },
   "outputs": [],
   "source": [
    "pip install langchain==0.3.7\n",
    "pip install langchain-chroma==0.1.4\n",
    "pip install langchain-community==0.3.5\n",
    "pip install langchain-core==0.3.18\n",
    "pip install langchain-huggingface==0.1.2\n",
    "pip install langchain-ollama==0.2.0\n",
    "pip install langchain-openai==0.2.8\n",
    "pip install langchain-text-splitters==0.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 openai 接口"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本地 ollama 已部署 `qwen2.5:14b` 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=' seems to be an unintended response and not relevant to your greeting. How can I assist you today? If you have any specific questions or topics related to LangChain (a framework for building applications with language models), feel free to ask!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 37, 'total_tokens': 85, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'qwen2.5:14b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None} id='run-114d7a82-7dc8-4240-9d0d-4cb94dd3a53d-0' usage_metadata={'input_tokens': 37, 'output_tokens': 48, 'total_tokens': 85, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "chat = ChatOpenAI(temperature=0, model_name=\"qwen2.5:14b\", openai_api_key='ollama', openai_api_base='http://localhost:11434/v1')\n",
    "response = chat.invoke([ HumanMessage(content=\"Hello Langchain!\")])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 zhipuai 接口"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要申请 zhipuai 的key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7t2nQzTEGXy1",
    "outputId": "b01545bc-b27e-4544-d527-adad64c0bfe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello! How can I assist you today? If you have any questions or need information on a topic, feel free to ask.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 9, 'total_tokens': 37}, 'model_name': 'glm-4', 'finish_reason': 'stop'} id='run-1799a23e-6fe9-4e26-9212-adeb25a37f73-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "import os\n",
    "os.environ['ZHIPUAI_API_KEY'] = '你的 api key'\n",
    "\n",
    "chat = ChatZhipuAI(temperature=0, model=\"glm-4\")\n",
    "response = chat.invoke([ HumanMessage(content=\"Hello Langchain!\") ])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
